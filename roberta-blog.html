<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building ML for Teacher Selection: When Getting It Wrong Means Leaving Kids Behind</title>
    <style>
        :root {
            --teal: #5eadbd;
            --teal-light: #e8f4f6;
            --gray: #555;
            --gray-light: #777;
            --gray-lighter: #e0e0e0;
            --black: #2c2c2c;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
            line-height: 1.7;
            color: var(--black);
            background: #ffffff;
            padding-top: 70px;
        }

        nav {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid var(--gray-lighter);
            z-index: 1000;
        }

        nav .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px 40px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        nav .logo {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--black);
            text-decoration: none;
        }

        nav .nav-links {
            display: flex;
            gap: 30px;
        }

        nav .nav-links a {
            color: var(--gray);
            text-decoration: none;
            font-size: 0.95rem;
            transition: color 0.3s;
        }

        nav .nav-links a:hover {
            color: var(--teal);
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 0 40px;
        }

        .back-link {
            padding: 80px 0 30px;
        }

        .back-link a {
            color: var(--teal);
            text-decoration: none;
            font-size: 0.95rem;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }

        .back-link a:hover {
            text-decoration: underline;
        }

        .post-header {
            padding: 20px 0 50px;
            border-bottom: 1px solid var(--gray-lighter);
        }

        .post-header h1 {
            font-size: 2.5rem;
            line-height: 1.2;
            margin-bottom: 20px;
            color: var(--black);
        }

        .post-meta {
            color: var(--gray-light);
            font-size: 0.95rem;
        }

        .post-content {
            padding: 60px 0;
        }

        .post-content h2 {
            font-size: 1.8rem;
            margin: 50px 0 25px;
            color: var(--black);
        }

        .post-content h3 {
            font-size: 1.3rem;
            margin: 40px 0 20px;
            color: var(--black);
        }

        .post-content p {
            margin-bottom: 20px;
            font-size: 1.05rem;
        }

        .post-content ul, .post-content ol {
            margin: 20px 0 20px 25px;
        }

        .post-content li {
            margin-bottom: 10px;
            font-size: 1.05rem;
        }

        .post-content strong {
            color: var(--black);
            font-weight: 600;
        }

        .post-content pre {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 6px;
            overflow-x: auto;
            margin: 25px 0;
            font-size: 0.9rem;
            border: 1px solid var(--gray-lighter);
        }

        .post-content code {
            font-family: 'Monaco', 'Courier New', monospace;
        }

        .post-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
        }

        .post-content table th,
        .post-content table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid var(--gray-lighter);
        }

        .post-content table th {
            background: var(--teal-light);
            font-weight: 600;
            color: var(--black);
        }

        .callout-box {
            background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
            border: 3px solid #e74c3c;
            border-radius: 12px;
            padding: 30px 40px;
            margin: 40px 0;
            text-align: center;
        }

        .callout-box h3 {
            color: #c0392b;
            font-size: 1.5rem;
            margin: 0 0 20px 0;
            letter-spacing: 1px;
        }

        .callout-box p {
            font-size: 1.15rem;
            line-height: 1.6;
            margin-bottom: 12px;
            color: #2c3e50;
        }

        .callout-box p:last-child {
            margin-bottom: 0;
            font-style: italic;
            font-size: 1.05rem;
        }

        .callout-box .emphasis {
            font-weight: 700;
            color: #2c3e50;
        }

        .kicker {
            background: var(--teal-light);
            border-left: 4px solid var(--teal);
            padding: 25px 30px;
            margin: 50px 0 30px;
            font-size: 1.2rem;
            font-weight: 500;
            font-style: italic;
            color: var(--black);
            line-height: 1.6;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 30px auto;
            border-radius: 8px;
        }

        @media (max-width: 768px) {
            body {
                padding-top: 60px;
            }

            nav .container {
                padding: 15px 25px;
            }

            .container {
                padding: 0 25px;
            }

            .post-header h1 {
                font-size: 2rem;
            }

            .post-content h2 {
                font-size: 1.5rem;
            }

            .post-content h3 {
                font-size: 1.2rem;
            }

            .callout-box {
                padding: 25px 20px;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="container">
            <a href="index.html" class="logo">Niranjan Prakash</a>
            <div class="nav-links">
                <a href="index.html#about">About</a>
                <a href="index.html#experience">Experience</a>
                <a href="index.html#projects">Projects</a>
                <a href="blog.html">Blog</a>
            </div>
        </div>
    </nav>

    <!-- Back Link -->
    <div class="container">
        <div class="back-link">
            <a href="blog.html">← Back to Blog</a>
        </div>
    </div>

    <!-- Post Header -->
    <div class="container">
        <div class="post-header">
            <h1>Building ML for Teacher Selection: When Getting It Wrong Means Leaving Kids Behind</h1>
            <div class="post-meta">
                <span>December 2024</span>
            </div>
        </div>
    </div>

    <!-- Post Content -->
    <article class="post-content">
        <div class="container">
            
            <!-- A. OPENING STORY -->
            <p>I spent two years as a Teach For India Fellow in Ahmedabad, teaching Math and Science to 200 students in a low-income private school. It was the hardest thing I've ever done. I was managing limited resources, navigating relationships with parents and school administration, dealing with the beautiful chaos of adolescents being adolescents, and carrying the weight of knowing these kids deserved better than what the education system had given them.</p>

            <p>Some days, I genuinely questioned whether I could keep going. But I did. Because leaving mid-year would have meant those 200 students losing yet another teacher, falling further behind, and learning—again—that adults don't keep their commitments.</p>

            <p>Not every Fellow makes it through the two-year commitment. And when they don't, the students pay the price. Disrupted learning, lost relationships, and the message that maybe they're not worth sticking around for.</p>

            <p>The data backs this up: <strong>Fellows who score low on a key resilience trait are nearly twice as likely to leave before completing their commitment</strong> compared to those who meet the bar. Attrition isn't just a retention problem—it's an equity problem.</p>

            <!-- B. WHAT WE'RE REALLY PREDICTING -->
            <h2>What We're Really Predicting</h2>

            <p>The selection team calls it "grit," but what does that even mean? How do you measure someone's determination from a 500-word essay? How do you identify who has the resilience to show up every day for two years, even when it feels impossible?</p>

            <p>Teach For India scaled from 2 cities in 2010 to 9 cities by 2020, receiving over 20,000 fellowship applications annually. Each application includes essays describing ambitious commitments and responses to challenges. At this scale, manual evaluation becomes impossible.</p>

            <p><strong>Why not use ChatGPT?</strong> Three reasons:</p>
            <ul>
                <li><strong>Cost:</strong> Processing 20,000 essays through API calls adds up quickly—thousands of dollars per cycle</li>
                <li><strong>Speed:</strong> API latency creates bottlenecks during deadline weeks when hundreds of essays arrive daily</li>
                <li><strong>Control:</strong> TFI has 14,000 labeled essays from past cohorts—fine-tuning gives precise control over predictions</li>
            </ul>

            <!-- C. MODEL GOAL CALLOUT -->
            <div class="callout-box">
                <h3>THE MODEL'S JOB</h3>
                <p class="emphasis">We do NOT predict who will excel.</p>
                <p class="emphasis">We flag who will quit.</p>
                <p>Because the cost of missing that signal is measured in disrupted classrooms.</p>
            </div>

            <!-- D. TECHNICAL APPROACH -->
            <h2>Technical Approach</h2>

            <h3>The Data</h3>
            <p>14,000 labeled essays from previous cohorts, split 80/20 into training and test sets. The class distribution was severely imbalanced:</p>
            <ul>
                <li>Score 2: 6,000 essays (42%)</li>
                <li>Score 3: 4,422 essays (31%)</li>
                <li>Score 1: 3,006 essays (21%)</li>
                <li>Score 4: 806 essays (6%)</li>
                <li>Score 5: 70 essays (0.5%)</li>
            </ul>

            <h3>The Imbalance Choice</h3>
            <p><strong>Conventional ML wisdom: balance your classes.</strong><br>
            <strong>My choice: keep the imbalance.</strong></p>

            <p>Why? The fellowship is hard in a specific way. Most candidates are somewhere in the middle. Having 42% of essays scored as "2" meant the model saw tons of examples of "just meeting the bar." This imbalance encodes exactly the signal I needed: strong detection of at-risk candidates.</p>

            <h3>The Model: RoBERTa + Probability Distributions</h3>
            <p>Fine-tuned RoBERTa-base (125M parameters) with a critical architectural choice: output probability distributions instead of hard classifications.</p>

            <p><strong>Instead of:</strong> "This essay is a 2"<br>
            <strong>We get:</strong> "P(1)=12%, P(2)=68%, P(3)=18%, P(4)=2%, P(5)=0%"</p>

            <p>This uncertainty quantification became crucial in production. Even humans disagree on borderline cases—when the model is uncertain, those essays go to human review.</p>

            <img src="images/loss_curve_grit.png" alt="Training loss curves showing convergence over 4 epochs" style="max-width: 600px;">

            <h3>The Metric Choice: Recall on Low Scores</h3>
            <p><strong>Not optimizing for overall accuracy.</strong> Optimizing for: <strong>Can we catch candidates at risk of leaving?</strong></p>

            <p>This means maximizing recall on scores 1-2 (the critical class), even if it means lower overall accuracy.</p>

            <!-- E. RESULTS -->
            <h2>Results</h2>

            <p>I trained two models to validate the approach:</p>

            <p><strong>RoBERTa</strong> (production model):</p>
            <ul>
                <li>14k essays, natural imbalance</li>
                <li>49% overall accuracy</li>
                <li><strong>63% recall on score 1</strong> (catching at-risk candidates)</li>
            </ul>

            <p><strong>DeBERTa</strong> (balanced alternative):</p>
            <ul>
                <li>10k essays, rebalanced distribution</li>
                <li>52% overall accuracy ✓</li>
                <li><strong>43% recall on score 1</strong> ✗</li>
            </ul>

            <img src="images/results_composite.png" alt="Comparison showing RoBERTa outperforms DeBERTa on critical low-score detection despite lower overall accuracy">

            <p><strong>The "worse" model by traditional metrics was better for the actual task.</strong></p>

            <p>DeBERTa is better at predicting high scores, but those candidates pass through regardless. RoBERTa is 20 percentage points better at identifying low scores—the actual task that matters.</p>

            <p><strong>Takeaway:</strong> Optimize for the business problem, not the ML metric. My experience as a Fellow gave me the context to know which metric actually mattered.</p>

            <!-- F. PRODUCTION & IMPACT -->
            <h2>Production & Impact</h2>

            <h3>Deployment Architecture</h3>
            <ul>
                <li>HuggingFace Spaces (free tier) + Flask backend</li>
                <li>Weekly batch processing: ~300 essays (regular), ~600 (deadline periods)</li>
                <li>5 months in production: 10,000-15,000 essays processed</li>
                <li>Cold starts aren't an issue for batch processing</li>
            </ul>

            <h3>Human-in-the-Loop System</h3>
            <p>Model outputs feed into rule-based filtering combining essay scores with application data. Probability distributions enable intelligent flagging:</p>

            <pre><code>High confidence rejection:
P(1)=88%, P(2)=9%, P(3)=2%
→ Clear low score, no review needed

Uncertain case:
P(1)=11%, P(2)=46%, P(3)=33%
→ Most likely a 2, but could be 3
→ Flag for human review</code></pre>

            <img src="images/example_probability_distributions.png" alt="Real examples showing high confidence correct, high confidence wrong, and uncertain predictions">

            <h3>Impact Metrics</h3>
            <p><strong>Before automation:</strong></p>
            <ul>
                <li>3 team members manually scoring essays</li>
                <li>2-10 hours per week depending on volume</li>
                <li>6-30 person-hours per week on initial screening</li>
            </ul>

            <p><strong>After automation:</strong></p>
            <ul>
                <li>Model processes 300 essays in ~5 minutes</li>
                <li>Team focuses only on flagged cases (20-30%)</li>
                <li><strong>60% reduction in manual screening work</strong></li>
            </ul>

            <p><strong>More importantly:</strong> The selection team can now invest their expertise in nuanced evaluations rather than mechanical scoring.</p>

            <h3>Production Validation (5 Months)</h3>
            <p>Analyzed 1,443 essays from one complete application round:</p>
            <ul>
                <li><strong>471 (33%)</strong> filtered out automatically</li>
                <li><strong>972 (67%)</strong> sent to human review</li>
            </ul>

            <img src="images/system_flow_diagram.png" alt="System flow showing 1443 essays → 471 filtered + 972 reviewed → outcomes">

            <p>Of the 972 reviewed:</p>
            <ul>
                <li><strong>45% exact accuracy</strong> (predicting exact human score)</li>
                <li><strong>91% within-1 accuracy</strong> (within one score)</li>
                <li><strong>65% scored 3+</strong> (appropriately passed)</li>
                <li><strong>35% scored 1-2</strong> (at-risk candidates that needed review)</li>
            </ul>

            <img src="images/calibration_analysis.png" alt="Calibration showing confidence correlates with accuracy" style="max-width: 700px;">

            <p>The 35% "false positive" rate reflects conservative design: when uncertain, flag for review rather than auto-reject.</p>

            <!-- G. LESSONS LEARNED -->
            <h2>Lessons Learned</h2>

            <h3>1. Task Definition > Accuracy</h3>
            <p>A model with 49% accuracy beat one with 52% because it solved the right problem. If I'd optimized for overall accuracy, I would've deployed the wrong model. My experience as a Fellow gave me the context to know that false negatives (rejecting good candidates) are recoverable through review, but false positives (accepting candidates who leave) directly harm students.</p>

            <h3>2. Class Imbalance as Signal</h3>
            <p>Having 42% score-2 essays reflected reality: most applicants are in the middle. The fellowship is hard—not everyone thrives, but not everyone fails. The model seeing tons of "just meeting the bar" examples made it better at distinguishing score 2 (at risk) from score 3 (likely to persist).</p>

            <h3>3. Probability Distributions > Hard Classifications</h3>
            <p>Outputting probability distributions enabled confidence-based filtering, natural integration with human review workflows, and transparency about uncertainty—critical when decisions affect people's futures. Even humans disagree on borderline cases. A model that says "I'm uncertain" is more valuable than one forcing predictions.</p>

            <h3>4. Free Hosting for Nonprofit Budgets</h3>
            <p>HuggingFace Spaces free tier works for batch processing despite limitations (cold starts, potential downtime). Design your system to tolerate constraints: batch weekly instead of real-time, accept occasional cold starts, maintain fallback manual processes. Not every ML system needs enterprise infrastructure.</p>

            <h3>5. Human Context Shapes Technical Decisions</h3>
            <p>Every technical choice—keeping class imbalance, optimizing for recall on low scores, outputting probability distributions—was informed by understanding the human impact. I knew what it felt like to want to quit. I knew what happened to students when teachers left. That context shaped the model in ways purely technical optimization never would.</p>

            <!-- H. WHAT'S NEXT -->
            <h2>What's Next</h2>

            <p>The model has been running successfully for 5 months. Next steps:</p>

            <ul>
                <li><strong>Production monitoring:</strong> Collecting feedback from evaluators on flagged cases to measure real-world calibration and adjust confidence thresholds based on attrition data from recent cohorts</li>
                <li><strong>Expanding scope:</strong> Applying similar uncertainty-based approaches to other traits in the selection rubric, potentially building ensemble models that combine predictions across multiple dimensions</li>
            </ul>

            <!-- I. KICKER -->
            <div class="kicker">
                Sometimes the best ML model isn't the one with the highest accuracy. It's the one that keeps teachers in classrooms and keeps promises to kids who deserve better.
            </div>

        </div>
    </article>
</body>
</html>